{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d8e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install -q towhee towhee.models pillow ipython gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490d1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./reverse_video_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1b0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "id_video = df.set_index('id')['path'].to_dict()\n",
    "label_ids = {}\n",
    "for label in set(df['label']):\n",
    "    label_ids[label] = list(df[df['label']==label].id)\n",
    "\n",
    "def ground_truth(path):\n",
    "    print(\"Path received:\", path)\n",
    "    label = os.path.basename(os.path.dirname(path))\n",
    "    print(\"Extracted label:\", label)\n",
    "    if label not in label_ids:\n",
    "        print(\"Label not found in label_ids dictionary:\", label)\n",
    "    return label_ids.get(label, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4fbffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "connections.connect(host='localhost', port='19530')\n",
    "\n",
    "def create_milvus_collection(collection_name, dim):    \n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "    \n",
    "    fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='reverse video search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\": 400}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection\n",
    "\n",
    "collection = create_milvus_collection('x3d_m', 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2619b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n",
      "2024-04-25 09:23:49,627 - 7196 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:23:49,638 - 7196 - node.py-node:167 - INFO: Begin to run Node-read_csv-0\n",
      "2024-04-25 09:23:49,639 - 10084 - node.py-node:167 - INFO: Begin to run Node-lambda-1\n",
      "2024-04-25 09:23:49,649 - 7196 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-2\n",
      "2024-04-25 09:23:49,661 - 10084 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-3\n",
      "2024-04-25 09:23:49,661 - 1492 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-4\n",
      "2024-04-25 09:23:49,662 - 6832 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of inserted data is 220.\n"
     ]
    }
   ],
   "source": [
    "from towhee import pipe, ops\n",
    "from towhee.datacollection import DataCollection\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    import csv\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "        data = csv.DictReader(f)\n",
    "        for line in data:\n",
    "            yield line['id'], line['path'], line['label']\n",
    "\n",
    "\n",
    "insert_pipe = (\n",
    "    pipe.input('csv_path')\n",
    "        .flat_map('csv_path', ('id', 'path', 'label'), read_csv)\n",
    "        .map('id', 'id', lambda x: int(x))\n",
    "        .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 16}))\n",
    "        .map('frames', ('labels', 'scores', 'features'), ops.action_classification.pytorchvideo(model_name='x3d_m', skip_preprocess=True))\n",
    "        .map(('id', 'features'), 'insert_res', ops.ann_insert.milvus_client(host='127.0.0.1', port='19530', collection_name='x3d_m'))\n",
    "        .output()\n",
    ")\n",
    "\n",
    "insert_pipe('reverse_video_search.csv')\n",
    "print('Total number of inserted data is {}.'.format(collection.num_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e31a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n",
      "2024-04-25 09:39:38,615 - 11180 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:39:38,627 - 13124 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-0\n",
      "2024-04-25 09:39:38,628 - 17208 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-1\n",
      "2024-04-25 09:39:38,630 - 11180 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-2\n",
      "2024-04-25 09:39:38,635 - 16492 - node.py-node:167 - INFO: Begin to run Node-lambda-3\n",
      "2024-04-25 09:39:38,639 - 5960 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">path</th> <th style=\"text-align: center; font-size: 130%; border: none;\">candidates</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">./test/eating_carrots/ty4UQlowp0c.mp4</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \"><br>./train/eating_carrots/V7DUq0JJneY.mp4</br> <br>./train/eating_carrots/bTCznQiu0hc.mp4</br> <br>./train/eating_carrots/Ou1w86qEr58.mp4</br> <br>./train/eating_carrots/Ka6z9NtiVMQ.mp4</br> <br>./train/eating_carrots/9OZhQqMhX50.mp4</br></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collection.load()\n",
    "\n",
    "query_path = './test/eating_carrots/ty4UQlowp0c.mp4'\n",
    "\n",
    "query_pipe = (\n",
    "    pipe.input('path')\n",
    "        .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 16}))\n",
    "        .map('frames', ('labels', 'scores', 'features'), ops.action_classification.pytorchvideo(model_name='x3d_m', skip_preprocess=True))\n",
    "        .map('features', 'result', ops.ann_search.milvus_client(host='127.0.0.1', port='19530', collection_name='x3d_m', limit=10))  \n",
    "        .map('result', 'candidates', lambda x: [id_video[i[0]] for i in x])\n",
    "        .output('path', 'candidates')\n",
    ")\n",
    "\n",
    "res = DataCollection(query_pipe(query_path))\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58bfe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 09:39:49,532 - 5700 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:39:49,541 - 14900 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-0\n",
      "2024-04-25 09:39:49,550 - 7724 - node.py-node:167 - INFO: Begin to run Node-_output\n",
      "2024-04-25 09:39:51,948 - 13820 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:39:51,950 - 16464 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-0\n",
      "2024-04-25 09:39:51,951 - 16456 - node.py-node:167 - INFO: Begin to run Node-_output\n",
      "2024-04-25 09:39:54,650 - 5704 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:39:54,655 - 4772 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-0\n",
      "2024-04-25 09:39:54,656 - 5704 - node.py-node:167 - INFO: Begin to run Node-_output\n",
      "2024-04-25 09:39:55,810 - 13968 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:39:55,812 - 3344 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-0\n",
      "2024-04-25 09:39:55,813 - 13968 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Query video \"eating_carrots\": <br/><img src=\"./tmp\\ty4UQlowp0c.gif\"> <br/>Top 3 search results: <br/><img src=\"./tmp\\V7DUq0JJneY.gif\" style=\"display:inline;margin:1px\"/><img src=\"./tmp\\bTCznQiu0hc.gif\" style=\"display:inline;margin:1px\"/><img src=\"./tmp\\Ou1w86qEr58.gif\" style=\"display:inline;margin:1px\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "\n",
    "tmp_dir = './tmp'\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "def video_to_gif(video_path):\n",
    "    gif_path = os.path.join(tmp_dir, video_path.split('/')[-1][:-4] + '.gif')\n",
    "    p = (\n",
    "        pipe.input('path')\n",
    "            .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 16}))\n",
    "            .output('frames')\n",
    "    )\n",
    "    frames = p(video_path).get()[0]\n",
    "    imgs = [Image.fromarray(frame) for frame in frames]\n",
    "    imgs[0].save(fp=gif_path, format='GIF', append_images=imgs[1:], save_all=True, loop=0)\n",
    "    return gif_path\n",
    "\n",
    "html = 'Query video \"{}\": <br/>'.format(query_path.split('/')[-2])\n",
    "query_gif = video_to_gif(query_path)\n",
    "html_line = '<img src=\"{}\"> <br/>'.format(query_gif)\n",
    "html +=  html_line\n",
    "html += 'Top 3 search results: <br/>'\n",
    "\n",
    "for path in res[0]['candidates'][:3]:\n",
    "    gif_path = video_to_gif(path)\n",
    "    html_line = '<img src=\"{}\" style=\"display:inline;margin:1px\"/>'.format(gif_path)\n",
    "    html +=  html_line\n",
    "display.HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d468a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n",
      "2024-04-25 09:40:09,053 - 9372 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 09:40:09,057 - 13600 - node.py-node:167 - INFO: Begin to run Node-lambda-0\n",
      "2024-04-25 09:40:09,058 - 9372 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2024-04-25 09:40:09,061 - 15832 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-2\n",
      "2024-04-25 09:40:09,065 - 15868 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-3\n",
      "2024-04-25 09:40:09,066 - 2172 - node.py-node:167 - INFO: Begin to run Node-lambda-4\n",
      "2024-04-25 09:40:09,077 - 16996 - node.py-node:167 - INFO: Begin to run Node-ground_truth-5\n",
      "2024-04-25 09:40:09,078 - 1988 - node.py-node:167 - INFO: Begin to run Node-mean_hit_ratio-6\n",
      "2024-04-25 09:40:09,086 - 14900 - node.py-node:167 - INFO: Begin to run Node-mean_average_precision-7\n",
      "2024-04-25 09:40:09,107 - 13600 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path received: ./test\\chopping_wood\\kDuAS29BCwk.mp4\n",
      "Extracted label: chopping_wood\n",
      "Path received: ./test\\clay_pottery_making\\QRQfX7aUPqs.mp4\n",
      "Extracted label: clay_pottery_making\n",
      "Path received: ./test\\country_line_dancing\\1TzGn3qcsTk.mp4\n",
      "Extracted label: country_line_dancing\n",
      "Path received: ./test\\dancing_gangnam_style\\LhZSA_QY8Fg.mp4\n",
      "Extracted label: dancing_gangnam_style\n",
      "Path received: ./test\\doing_aerobics\\r63FpwJ9dik.mp4\n",
      "Extracted label: doing_aerobics\n",
      "Path received: ./test\\drop_kicking\\ONMjPkk2x0Y.mp4\n",
      "Extracted label: drop_kicking\n",
      "Path received: ./test\\dunking_basketball\\y_-ivQSPV0Q.mp4\n",
      "Extracted label: dunking_basketball\n",
      "Path received: ./test\\eating_carrots\\ty4UQlowp0c.mp4\n",
      "Extracted label: eating_carrots\n",
      "Path received: ./test\\eating_hotdog\\rJu8mSNHX_8.mp4\n",
      "Extracted label: eating_hotdog\n",
      "Path received: ./test\\javelin_throw\\ZmBDBldVa74.mp4\n",
      "Extracted label: javelin_throw\n",
      "Path received: ./test\\juggling_fire\\umd-9rS3hQg.mp4\n",
      "Extracted label: juggling_fire\n",
      "Path received: ./test\\juggling_soccer_ball\\bH9cE46eZJY.mp4\n",
      "Extracted label: juggling_soccer_ball\n",
      "Path received: ./test\\playing_trombone\\iiJS7YTT5Gs.mp4\n",
      "Extracted label: playing_trombone\n",
      "Path received: ./test\\pumping_fist\\t6-eBFhPsxo.mp4\n",
      "Extracted label: pumping_fist\n",
      "Path received: ./test\\pushing_cart\\esDMtgFIAtQ.mp4\n",
      "Extracted label: pushing_cart\n",
      "Path received: ./test\\riding_mule\\2uzRsYqIwy4.mp4\n",
      "Extracted label: riding_mule\n",
      "Path received: ./test\\shuffling_cards\\8oy1RNINVfQ.mp4\n",
      "Extracted label: shuffling_cards\n",
      "Path received: ./test\\tap_dancing\\EC3Jzrs_mNA.mp4\n",
      "Extracted label: tap_dancing\n",
      "Path received: ./test\\trimming_trees\\dxe9LkBB4Q8.mp4\n",
      "Extracted label: trimming_trees\n",
      "Path received: ./test\\using_segway\\DqtwXBrKv24.mp4\n",
      "Extracted label: using_segway\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">mHR</th> <th style=\"text-align: center; font-size: 130%; border: none;\">mAP</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.345</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.7013333333333333</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def mean_hit_ratio(actual, predicted):\n",
    "    ratios = []\n",
    "    for act, pre in zip(actual, predicted):\n",
    "        hit_num = len(set(act) & set(pre))\n",
    "        ratios.append(hit_num / len(act))\n",
    "    return sum(ratios) / len(ratios)\n",
    "\n",
    "def mean_average_precision(actual, predicted):\n",
    "    aps = []\n",
    "    for act, pre in zip(actual, predicted):\n",
    "        precisions = []\n",
    "        hit = 0\n",
    "        for idx, i in enumerate(pre):\n",
    "            if i in act:\n",
    "                hit += 1\n",
    "            precisions.append(hit / (idx + 1))\n",
    "        aps.append(sum(precisions) / len(precisions))\n",
    "    \n",
    "    return sum(aps) / len(aps)\n",
    "\n",
    "eval_pipe = (\n",
    "    pipe.input('path')\n",
    "        .flat_map('path', 'path', lambda x: glob.glob(x))\n",
    "        .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 16}))\n",
    "        .map('frames', ('labels', 'scores', 'features'), ops.action_classification.pytorchvideo(model_name='x3d_m', skip_preprocess=True))\n",
    "        .map('features', 'result', ops.ann_search.milvus_client(host='127.0.0.1', port='19530', collection_name='x3d_m', limit=10))  \n",
    "        .map('result', 'predict', lambda x: [i[0] for i in x])\n",
    "        .map('path', 'ground_truth', ground_truth)\n",
    "        .window_all(('ground_truth', 'predict'), 'mHR', mean_hit_ratio)\n",
    "        .window_all(('ground_truth', 'predict'), 'mAP', mean_average_precision)\n",
    "        .output('mHR', 'mAP')\n",
    ")\n",
    "\n",
    "res = DataCollection(eval_pipe('./test/*/*.mp4'))\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04489af1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n",
      "2024-04-24 12:26:08,512 - 10224 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-24 12:26:08,521 - 10224 - node.py-node:167 - INFO: Begin to run Node-read_csv-0\n",
      "2024-04-24 12:26:08,523 - 3944 - node.py-node:167 - INFO: Begin to run Node-lambda-1\n",
      "2024-04-24 12:26:08,523 - 16320 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-2\n",
      "2024-04-24 12:26:08,524 - 1696 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-3\n",
      "2024-04-24 12:26:08,536 - 9600 - node.py-node:167 - INFO: Begin to run Node-towhee/np-normalize-4\n",
      "2024-04-24 12:26:08,540 - 10224 - node.py-node:167 - INFO: Begin to run Node-ann-insert/milvus-client-5\n",
      "2024-04-24 12:26:08,541 - 5424 - node.py-node:167 - INFO: Begin to run Node-_output\n",
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n",
      "2024-04-24 12:29:59,700 - 17184 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-24 12:29:59,715 - 16388 - node.py-node:167 - INFO: Begin to run Node-lambda-0\n",
      "2024-04-24 12:29:59,716 - 2412 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2024-04-24 12:29:59,717 - 6908 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-2\n",
      "2024-04-24 12:29:59,720 - 17184 - node.py-node:167 - INFO: Begin to run Node-towhee/np-normalize-3\n",
      "2024-04-24 12:29:59,720 - 7492 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-4\n",
      "2024-04-24 12:29:59,726 - 14880 - node.py-node:167 - INFO: Begin to run Node-lambda-5\n",
      "2024-04-24 12:29:59,728 - 3788 - node.py-node:167 - INFO: Begin to run Node-ground_truth-6\n",
      "2024-04-24 12:29:59,730 - 5920 - node.py-node:167 - INFO: Begin to run Node-mean_hit_ratio-7\n",
      "2024-04-24 12:29:59,749 - 16388 - node.py-node:167 - INFO: Begin to run Node-mean_average_precision-8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path received: ./test\\chopping_wood\\kDuAS29BCwk.mp4\n",
      "Extracted label: chopping_wood\n",
      "Path received: ./test\\clay_pottery_making\\QRQfX7aUPqs.mp4\n",
      "Extracted label: clay_pottery_making\n",
      "Path received: ./test\\country_line_dancing\\1TzGn3qcsTk.mp4\n",
      "Extracted label: country_line_dancing\n",
      "Path received: ./test\\dancing_gangnam_style\\LhZSA_QY8Fg.mp4\n",
      "Extracted label: dancing_gangnam_style\n",
      "Path received: ./test\\doing_aerobics\\r63FpwJ9dik.mp4\n",
      "Extracted label: doing_aerobics\n",
      "Path received: ./test\\drop_kicking\\ONMjPkk2x0Y.mp4\n",
      "Extracted label: drop_kicking\n",
      "Path received: ./test\\dunking_basketball\\y_-ivQSPV0Q.mp4\n",
      "Extracted label: dunking_basketball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 12:30:12,849 - 2412 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path received: ./test\\eating_carrots\\ty4UQlowp0c.mp4\n",
      "Extracted label: eating_carrots\n",
      "Path received: ./test\\eating_hotdog\\rJu8mSNHX_8.mp4\n",
      "Extracted label: eating_hotdog\n",
      "Path received: ./test\\javelin_throw\\ZmBDBldVa74.mp4\n",
      "Extracted label: javelin_throw\n",
      "Path received: ./test\\juggling_fire\\umd-9rS3hQg.mp4\n",
      "Extracted label: juggling_fire\n",
      "Path received: ./test\\juggling_soccer_ball\\bH9cE46eZJY.mp4\n",
      "Extracted label: juggling_soccer_ball\n",
      "Path received: ./test\\playing_trombone\\iiJS7YTT5Gs.mp4\n",
      "Extracted label: playing_trombone\n",
      "Path received: ./test\\pumping_fist\\t6-eBFhPsxo.mp4\n",
      "Extracted label: pumping_fist\n",
      "Path received: ./test\\pushing_cart\\esDMtgFIAtQ.mp4\n",
      "Extracted label: pushing_cart\n",
      "Path received: ./test\\riding_mule\\2uzRsYqIwy4.mp4\n",
      "Extracted label: riding_mule\n",
      "Path received: ./test\\shuffling_cards\\8oy1RNINVfQ.mp4\n",
      "Extracted label: shuffling_cards\n",
      "Path received: ./test\\tap_dancing\\EC3Jzrs_mNA.mp4\n",
      "Extracted label: tap_dancing\n",
      "Path received: ./test\\trimming_trees\\dxe9LkBB4Q8.mp4\n",
      "Extracted label: trimming_trees\n",
      "Path received: ./test\\using_segway\\DqtwXBrKv24.mp4\n",
      "Extracted label: using_segway\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border-collapse: collapse;\"><tr><th style=\"text-align: center; font-size: 130%; border: none;\">mHR</th> <th style=\"text-align: center; font-size: 130%; border: none;\">mAP</th></tr>\n",
       "<tr><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.66</td><td style=\"text-align: center; vertical-align: top; border-right: solid 1px #D3D3D3; border-left: solid 1px #D3D3D3; \">0.7376626984126984</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "collection = create_milvus_collection('x3d_m_norm', 2048)\n",
    "\n",
    "insert_pipe = (\n",
    "    pipe.input('csv_path')\n",
    "        .flat_map('csv_path', ('id', 'path', 'label'), read_csv)\n",
    "        .map('id', 'id', lambda x: int(x))\n",
    "        .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 16}))\n",
    "        .map('frames', ('labels', 'scores', 'features'), ops.action_classification.pytorchvideo(model_name='x3d_m', skip_preprocess=True))\n",
    "        .map('features', 'features', ops.towhee.np_normalize())\n",
    "        .map(('id', 'features'), 'insert_res', ops.ann_insert.milvus_client(host='127.0.0.1', port='19530', collection_name='x3d_m_norm'))\n",
    "        .output()\n",
    ")\n",
    "\n",
    "insert_pipe('reverse_video_search.csv')\n",
    "\n",
    "collection.load()\n",
    "eval_pipe = (\n",
    "    pipe.input('path')\n",
    "        .flat_map('path', 'path', lambda x: glob.glob(x))\n",
    "        .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 16}))\n",
    "        .map('frames', ('labels', 'scores', 'features'), ops.action_classification.pytorchvideo(model_name='x3d_m', skip_preprocess=True))\n",
    "        .map('features', 'features', ops.towhee.np_normalize())\n",
    "        .map('features', 'result', ops.ann_search.milvus_client(host='127.0.0.1', port='19530', collection_name='x3d_m_norm', limit=10))  \n",
    "        .map('result', 'predict', lambda x: [i[0] for i in x])\n",
    "        .map('path', 'ground_truth', ground_truth)\n",
    "        .window_all(('ground_truth', 'predict'), 'mHR', mean_hit_ratio)\n",
    "        .window_all(('ground_truth', 'predict'), 'mAP', mean_average_precision)\n",
    "        .output('mHR', 'mAP')\n",
    ")\n",
    "\n",
    "res = DataCollection(eval_pipe('./test/*/*.mp4'))\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n",
      "2024-04-25 10:33:59,374 - 12828 - connectionpool.py-connectionpool:1055 - DEBUG: Starting new HTTPS connection (1): api.gradio.app:443\n",
      "2024-04-25 10:33:59,381 - 12832 - connectionpool.py-connectionpool:1055 - DEBUG: Starting new HTTPS connection (1): api.gradio.app:443\n",
      "2024-04-25 10:33:59,749 - 12528 - selector_events.py-selector_events:54 - DEBUG: Using selector: SelectSelector\n",
      "2024-04-25 10:33:59,808 - 2612 - connectionpool.py-connectionpool:244 - DEBUG: Starting new HTTP connection (1): 127.0.0.1:7862\n",
      "2024-04-25 10:33:59,845 - 2612 - connectionpool.py-connectionpool:549 - DEBUG: http://127.0.0.1:7862 \"GET /startup-events HTTP/1.1\" 200 5\n",
      "2024-04-25 10:33:59,914 - 2612 - connectionpool.py-connectionpool:244 - DEBUG: Starting new HTTP connection (1): 127.0.0.1:7862\n",
      "2024-04-25 10:33:59,966 - 2612 - connectionpool.py-connectionpool:549 - DEBUG: http://127.0.0.1:7862 \"HEAD / HTTP/1.1\" 200 0\n",
      "2024-04-25 10:33:59,971 - 2612 - connectionpool.py-connectionpool:1055 - DEBUG: Starting new HTTPS connection (1): api.gradio.app:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 10:34:01,983 - 12832 - connectionpool.py-connectionpool:549 - DEBUG: https://api.gradio.app:443 \"GET /pkg-version HTTP/1.1\" 200 21\n",
      "2024-04-25 10:34:02,002 - 12828 - connectionpool.py-connectionpool:549 - DEBUG: https://api.gradio.app:443 \"POST /gradio-initiated-analytics/ HTTP/1.1\" 200 None\n",
      "2024-04-25 10:34:05,146 - 2612 - connectionpool.py-connectionpool:549 - DEBUG: https://api.gradio.app:443 \"GET /v2/tunnel-request HTTP/1.1\" 200 None\n",
      "2024-04-25 10:34:05,153 - 2612 - connectionpool.py-connectionpool:1055 - DEBUG: Starting new HTTPS connection (1): cdn-media.huggingface.co:443\n",
      "2024-04-25 10:34:07,376 - 2612 - connectionpool.py-connectionpool:549 - DEBUG: https://cdn-media.huggingface.co:443 \"GET /frpc-gradio-0.2/frpc_windows_amd64.exe HTTP/1.1\" 200 11681280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 10:34:20,916 - 14864 - connectionpool.py-connectionpool:1055 - DEBUG: Starting new HTTPS connection (1): api.gradio.app:443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 10:34:21,006 - 18972 - connectionpool.py-connectionpool:1055 - DEBUG: Starting new HTTPS connection (1): api.gradio.app:443\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 10:34:24,390 - 18972 - connectionpool.py-connectionpool:549 - DEBUG: https://api.gradio.app:443 \"POST /gradio-launched-telemetry/ HTTP/1.1\" 200 None\n",
      "2024-04-25 10:34:24,391 - 14864 - connectionpool.py-connectionpool:549 - DEBUG: https://api.gradio.app:443 \"POST /gradio-error-analytics/ HTTP/1.1\" 200 None\n",
      "2024-04-25 10:35:23,075 - 16848 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 10:35:23,105 - 10472 - node.py-node:167 - INFO: Begin to run Node-lambda-0\n",
      "2024-04-25 10:35:23,124 - 12972 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2024-04-25 10:35:23,131 - 16848 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-2\n",
      "2024-04-25 10:35:23,197 - 10472 - node.py-node:167 - INFO: Begin to run Node-towhee/np-normalize-3\n",
      "2024-04-25 10:35:23,199 - 16140 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-4\n",
      "2024-04-25 10:35:23,262 - 16496 - node.py-node:167 - INFO: Begin to run Node-lambda-5\n",
      "2024-04-25 10:35:23,276 - 13128 - node.py-node:167 - INFO: Begin to run Node-_output\n",
      "2024-04-25 10:36:40,239 - 12972 - node.py-node:167 - INFO: Begin to run Node-_input\n",
      "2024-04-25 10:36:40,256 - 16392 - node.py-node:167 - INFO: Begin to run Node-lambda-0\n",
      "2024-04-25 10:36:40,256 - 16848 - node.py-node:167 - INFO: Begin to run Node-video-decode/ffmpeg-1\n",
      "2024-04-25 10:36:40,258 - 10472 - node.py-node:167 - INFO: Begin to run Node-action-classification/pytorchvideo-2\n",
      "2024-04-25 10:36:40,258 - 16140 - node.py-node:167 - INFO: Begin to run Node-towhee/np-normalize-3\n",
      "2024-04-25 10:36:40,259 - 16496 - node.py-node:167 - INFO: Begin to run Node-ann-search/milvus-client-4\n",
      "2024-04-25 10:36:40,259 - 13128 - node.py-node:167 - INFO: Begin to run Node-lambda-5\n",
      "2024-04-25 10:36:40,260 - 14036 - node.py-node:167 - INFO: Begin to run Node-_output\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import video\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "video_search_pipe = (\n",
    "    pipe.input('path')\n",
    "        .flat_map('path', 'path', lambda x: glob.glob(x))\n",
    "        .map('path', 'frames', ops.video_decode.ffmpeg(sample_type='uniform_temporal_subsample', args={'num_samples': 32}))\n",
    "        .map('frames', ('labels', 'scores', 'features'), ops.action_classification.pytorchvideo(model_name='x3d_m', skip_preprocess=True))\n",
    "        .map('features', 'features', ops.towhee.np_normalize())\n",
    "        .map('features', 'result', ops.ann_search.milvus_client(host='127.0.0.1', port='19530', collection_name='x3d_m_norm', limit=3)) \n",
    "        .map('result', 'predict', lambda x: [id_video[i[0]] for i in x])\n",
    "        .output('predict')\n",
    ")\n",
    "\n",
    "\n",
    "def video_search_function(video):\n",
    "    return video_search_pipe(video).to_list()[0][0]\n",
    "\n",
    "interface = gradio.Interface(video_search_function, \n",
    "                             inputs=gradio.Video(source='upload'),\n",
    "                             outputs=[gradio.Video(format='mp4') for _ in range(3)]\n",
    "                            )\n",
    "\n",
    "interface.launch(inline=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7dd10cdbe9a9c71f7e71741efd428241b5f9fa0fecdd29ae07a5706cd5ff8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
